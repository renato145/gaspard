{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1629d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae282a",
   "metadata": {},
   "source": [
    "# Gaspard's source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4116139",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect, typing, mimetypes, base64, json, ast, os, time\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types.generation_types import GenerateContentResponse, GenerationConfig\n",
    "from google.generativeai.protos import FunctionCall, Content, FunctionResponse\n",
    "from google.generativeai.protos import GenerateContentResponse as GCR\n",
    "\n",
    "import toolslm\n",
    "from toolslm.funccall import *\n",
    "\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.utils import *\n",
    "\n",
    "from collections import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0764659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc\n",
    "\n",
    "try: from IPython import display\n",
    "except: display=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "UsageMetadata = GCR.UsageMetadata\n",
    "empty = inspect.Parameter.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "models = 'gemini-1.5-pro-exp-0827', 'gemini-1.5-flash-exp-0827','gemini-1.5-pro','gemini-1.5-flash'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a095bc",
   "metadata": {},
   "source": [
    "These are the latest version of Gemini models available at the time of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c81236",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99b6d9",
   "metadata": {},
   "source": [
    "We'll use gemini-1.5-flash for the examples since it's faster and cheaper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba835d",
   "metadata": {},
   "source": [
    "## Gemini SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a343d78",
   "metadata": {},
   "source": [
    "Follow the [instructions](https://aistudio.google.com/app/apikey) to generate an API key, and set it as an evironment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = genai.GenerativeModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62f521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Hello Faisal! It's nice to meet you.  What can I do for you today? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 8,\n",
       "        \"candidates_token_count\": 20,\n",
       "        \"total_token_count\": 28\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = cli.generate_content(\"Hi, I'm Faisal!\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae6c0b",
   "metadata": {},
   "source": [
    "## Formatting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97739d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def find_block(r:abc.Mapping, # The message to look in\n",
    "              ):\n",
    "    \"Find the content in `r`.\"\n",
    "    m = nested_idx(r, 'candidates', 0)\n",
    "    if not m: return m\n",
    "    if hasattr(m, 'content'): return m.content \n",
    "    else: return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b4144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parts {\n",
       "  text: \"Hello Faisal! It\\'s nice to meet you.  What can I do for you today? \\n\"\n",
       "}\n",
       "role: \"model\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_block(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def contents(r):\n",
    "    \"Helper to get the contents from response `r`.\"\n",
    "    blk = find_block(r)\n",
    "    if not blk: return r\n",
    "    if hasattr(blk, 'parts'): return getattr(blk,'parts')[0].text\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d7340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Faisal! It's nice to meet you.  What can I do for you today? \\n\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch()\n",
    "def _repr_markdown_(self:GenerateContentResponse):\n",
    "    met = list(self.to_dict()['candidates'][0].items()) + list(self.to_dict()['usage_metadata'].items())\n",
    "    det = '\\n- '.join(f'{k}: {v}' for k,v in met)\n",
    "    res = contents(self)\n",
    "    if not res: return f\"- {det}\"\n",
    "    return f\"\"\"{contents(self)}\n",
    "\n",
    "<details>\n",
    "\n",
    "- {det}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Faisal! It's nice to meet you.  What can I do for you today? \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': \"Hello Faisal! It's nice to meet you.  What can I do for you today? \\n\"}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 8\n",
       "- candidates_token_count: 20\n",
       "- total_token_count: 28\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Hello Faisal! It's nice to meet you.  What can I do for you today? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 8,\n",
       "        \"candidates_token_count\": 20,\n",
       "        \"total_token_count\": 28\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b541b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_token_count: 8\n",
       "candidates_token_count: 20\n",
       "total_token_count: 28"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61918cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def usage(inp=0, # Number of input tokens\n",
    "          out=0  # Number of output tokens\n",
    "         ):\n",
    "    \"Slightly more concise version of `Usage`.\"\n",
    "    return UsageMetadata(prompt_token_count=inp, candidates_token_count=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_token_count: 5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch(as_prop=True)\n",
    "def total(self:UsageMetadata): return self.prompt_token_count+self.candidates_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __repr__(self:UsageMetadata): return f'In: {self.prompt_token_count}; Out: {self.candidates_token_count}; Total: {self.total}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6780c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 8; Out: 20; Total: 28"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fafcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __add__(self:UsageMetadata, b):\n",
    "    \"Add together each of `input_tokens` and `output_tokens`\"\n",
    "    return usage(self.prompt_token_count+b.prompt_token_count, self.candidates_token_count+b.candidates_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 16; Out: 40; Total: 56"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage_metadata+r.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134bc41b",
   "metadata": {},
   "source": [
    "## Creating messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_msg(content, role='user', **kw):\n",
    "    if isinstance(content, GenerateContentResponse): return find_block(content)\n",
    "    if not isinstance(content, list): content=[content]\n",
    "    return dict(role=role, parts=content, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924dece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user', 'parts': [\"I'm Faisal\"]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I'm Faisal\"\n",
    "m = mk_msg(prompt)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Faisal! What can I do for you today? \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'Nice to meet you, Faisal! What can I do for you today? \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 5\n",
       "- candidates_token_count: 16\n",
       "- total_token_count: 21\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Nice to meet you, Faisal! What can I do for you today? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 5,\n",
       "        \"candidates_token_count\": 16,\n",
       "        \"total_token_count\": 21\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = cli.generate_content([m], generation_config=GenerationConfig(max_output_tokens=100))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ede3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'parts': [\"I'm Faisal\"]},\n",
       " parts {\n",
       "   text: \"Nice to meet you, Faisal! What can I do for you today? \\n\"\n",
       " }\n",
       " role: \"model\",\n",
       " {'role': 'user', 'parts': ['I forgot my name. Can you remind me please?']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [mk_msg(prompt), mk_msg(r), mk_msg('I forgot my name. Can you remind me please?')]\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708fc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You're right, you told me your name is Faisal! ðŸ˜„  \n",
       "\n",
       "Is there anything else I can help you with? \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': \"You're right, you told me your name is Faisal! ðŸ˜„  \\n\\nIs there anything else I can help you with? \\n\"}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 35\n",
       "- candidates_token_count: 26\n",
       "- total_token_count: 61\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"You're right, you told me your name is Faisal! \\ud83d\\ude04  \\n\\nIs there anything else I can help you with? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 35,\n",
       "        \"candidates_token_count\": 26,\n",
       "        \"total_token_count\": 61\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli.generate_content(msgs, generation_config=GenerationConfig(max_output_tokens=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec007f7f",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05864cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Client:\n",
    "    def __init__(self, model, cli=None, sp=None):\n",
    "        \"Basic LLM messages client.\"\n",
    "        self.model,self.use = model,usage(0,0)\n",
    "        self.sp = sp\n",
    "        self.c = (cli or genai.GenerativeModel(model, system_instruction=sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db82494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 0; Out: 0; Total: 0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Client(model)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198eac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _r(self:Client, r:GenerateContentResponse):\n",
    "    \"Store the result of the message and accrue total usage.\"\n",
    "    self.result = r\n",
    "    if getattr(r,'usage_metadata',None): self.use += r.usage_metadata\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8466e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 5; Out: 16; Total: 21"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c87c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_stream(r):\n",
    "    for o in r:\n",
    "        o = contents(o)\n",
    "        if o and isinstance(o, str): yield(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _set_sp(self:Client, sp:str):\n",
    "    if sp != self.sp:\n",
    "        self.sp = sp\n",
    "        self.c = genai.GenerativeModel(model, system_instruction=self.sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5166bd",
   "metadata": {},
   "source": [
    "Gemini cli requires passing the system prompt when creating the client, so we recreate the client for now.\n",
    "\n",
    "TODO: Ask Google to surface this option to generate_content function, since they're passing the system prompt to each request anyways [under the hood](https://github.com/googleapis/python-aiplatform/blob/f89df1f30822d260176487f74c3743cab88a38fd/vertexai/generative_models/_generative_models.py#L446)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bac993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(genai.GenerativeModel.generate_content)\n",
    "def __call__(self:Client,\n",
    "             msgs:list, # List of messages in the dialog\n",
    "             sp:str=None, # System prompt\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             stream:bool=False, # Stream response?\n",
    "             **kwargs):\n",
    "    \"Make a call to LLM.\"\n",
    "    if sp: self._set_sp(sp)\n",
    "    gc_params = inspect.signature(GenerationConfig.__init__).parameters\n",
    "    gc_kwargs = {k: v for k, v in kwargs.items() if k in gc_params}\n",
    "    gen_config = GenerationConfig(max_output_tokens=maxtok, **gc_kwargs)\n",
    "    gen_params = inspect.signature(self.c.generate_content).parameters\n",
    "    gen_kwargs = {k: v for k, v in kwargs.items() if k in gen_params}\n",
    "    r = self.c.generate_content(\n",
    "        contents=msgs, generation_config=gen_config, stream=stream, **gen_kwargs)\n",
    "    if not stream: return self._r(r)\n",
    "    else: return get_stream(map(self._r, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [mk_msg('Hi!')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50775d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi there! What can I do for you today? \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'Hi there! What can I do for you today? \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 3\n",
       "- candidates_token_count: 12\n",
       "- total_token_count: 15\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Hi there! What can I do for you today? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 3,\n",
       "        \"candidates_token_count\": 12,\n",
       "        \"total_token_count\": 15\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb4ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 8; Out: 28; Total: 36"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97727a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! What can I do for you today? \n"
     ]
    }
   ],
   "source": [
    "for o in c(msgs, stream=True): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37358f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 14; Out: 41; Total: 55"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c36641",
   "metadata": {},
   "source": [
    "Gemini cli requires passing the system prompt when creating the client, but we didn't pass one at creation time.\n",
    "Let's make sure that it gets set properly when we call the client later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysp = \"Respond only in emojis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a978d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ðŸ‘‹ \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'ðŸ‘‹ \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 7\n",
       "- candidates_token_count: 1\n",
       "- total_token_count: 8\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"\\ud83d\\udc4b \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 7,\n",
       "        \"candidates_token_count\": 1,\n",
       "        \"total_token_count\": 8\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(msgs, sp=sysp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dee9a",
   "metadata": {},
   "source": [
    "## Tool Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    a:int,  # First thing to sum\n",
    "    b:int # Second thing to sum\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    print(f\"Finding the sum of {a} and {b}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysp = \"You are a helpful assistant. When using tools, be sure to pass all required parameters, at minimum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ec83c",
   "metadata": {},
   "source": [
    "Google's Genai API handles schema exatraction under the hood, so we can just directly pass the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f714d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- content: {'parts': [{'function_call': {'name': 'sums', 'args': {'a': 604542.0, 'b': 6458932.0}}}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 10, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 9, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 86\n",
       "- candidates_token_count: 29\n",
       "- total_token_count: 115\n",
       "- cached_content_token_count: 0"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"sums\",\n",
       "                  \"args\": {\n",
       "                    \"a\": 604542.0,\n",
       "                    \"b\": 6458932.0\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 86,\n",
       "        \"candidates_token_count\": 29,\n",
       "        \"total_token_count\": 115\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [mk_msg(pr)]\n",
    "r = c(msgs, sp=sysp, tools=[sums])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441a121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parts {\n",
       "  function_call {\n",
       "    name: \"sums\"\n",
       "    args {\n",
       "      fields {\n",
       "        key: \"b\"\n",
       "        value {\n",
       "          number_value: 6458932\n",
       "        }\n",
       "      }\n",
       "      fields {\n",
       "        key: \"a\"\n",
       "        value {\n",
       "          number_value: 604542\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "role: \"model\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = find_block(r)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e621d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"sums\"\n",
       "args {\n",
       "  fields {\n",
       "    key: \"b\"\n",
       "    value {\n",
       "      number_value: 6458932\n",
       "    }\n",
       "  }\n",
       "  fields {\n",
       "    key: \"a\"\n",
       "    value {\n",
       "      number_value: 604542\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = m.parts[0].function_call\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _mk_ns(*funcs:list[callable]) -> dict[str,callable]:\n",
    "    \"Create a `dict` of name to function in `funcs`, to use as a namespace\"\n",
    "    return {f.__name__:f for f in funcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def call_func(fc:FunctionCall, # FunctionCall block from the response\n",
    "              ns:Optional[abc.Mapping]=None, # Namespace to search for tools, defaults to `globals()`\n",
    "              obj:Optional=None # Object to search for tools\n",
    "             ):\n",
    "    \"Call the function in the tool response `tr`, using namespace `ns`.\"\n",
    "    if ns is None: ns=globals()\n",
    "    if not isinstance(ns, abc.Mapping): ns = _mk_ns(*ns)\n",
    "    func = getattr(obj, fc.name, None)\n",
    "    if not func: func = ns[fc.name]\n",
    "    return func(**(fc.args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d387b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542.0 and 6458932.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7063474.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = _mk_ns(sums)\n",
    "res = call_func(func, ns=ns)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b788a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_toolres(\n",
    "    r:abc.Mapping, # Tool use request response\n",
    "    ns:Optional[abc.Mapping]=None, # Namespace to search for tools\n",
    "    obj:Optional=None # Class to search for tools\n",
    "    ):\n",
    "    \"Create a `tool_result` message from response `r`.\"\n",
    "    parts = find_block(r).parts\n",
    "    tcs = [p.function_call for p in parts if hasattr(p, 'function_call')]\n",
    "    res = [mk_msg(r)]\n",
    "    tc_res = []\n",
    "    for func in (tcs or []):\n",
    "        if not func: continue\n",
    "        cts = str(call_func(func, ns=ns, obj=obj))\n",
    "        tc_res.append(FunctionResponse(name=func.name, response={'result': cts}))\n",
    "    if tc_res: res.append(mk_msg(tc_res, 'function'))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec7457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542.0 and 6458932.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'function',\n",
       " 'parts': [name: \"sums\"\n",
       "  response {\n",
       "    fields {\n",
       "      key: \"result\"\n",
       "      value {\n",
       "        string_value: \"7063474.0\"\n",
       "      }\n",
       "    }\n",
       "  }]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = mk_toolres(r, ns=ns)\n",
    "tr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs += tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1a15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "7063474.0 \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': '7063474.0 \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 138\n",
       "- candidates_token_count: 9\n",
       "- total_token_count: 147\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"7063474.0 \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 138,\n",
       "        \"candidates_token_count\": 9,\n",
       "        \"total_token_count\": 147\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = c(msgs, sp=sysp, tools=[sums])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787ff76",
   "metadata": {},
   "source": [
    "We can also use tool calling to force the model to return structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Client.__call__)\n",
    "def structured(self:Client,\n",
    "               msgs:list, # List of messages in the dialog\n",
    "               ns:Optional[abc.Mapping]=None, # Namespace to search for tools\n",
    "               obj:Optional=None, # Class to search for tools\n",
    "               **kwargs):\n",
    "    \"Return the value of all tool calls (generally used for structured outputs)\"\n",
    "    res = self(msgs, **kwargs)\n",
    "    if ns is None: ns=globals()\n",
    "    parts = find_block(res).parts\n",
    "    funcs = [p.function_call for p in parts if hasattr(p, 'function_call')]\n",
    "    tcs = [call_func(func, ns=ns, obj=obj) for func in funcs]\n",
    "    return tcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15813bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recipe:\n",
    "    \"\"\"\n",
    "    A structure for representing recipes.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 recipe_name: str, # The name of the recipe   \n",
    "                 ingredients: list[str] # The igredients needed for the recipe\n",
    "                ):\n",
    "        store_attr()\n",
    "        \n",
    "    __repr__ = basic_repr(['recipe_name', 'ingredients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf6def5",
   "metadata": {},
   "source": [
    "Gemini API schema extraction doesn't work very well for Class definitions so we define a factory method as a workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f33ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recipe(recipe_name: str, # The name of the recipe   \n",
    "                 ingredients: list[str] # The igredients needed for the recipe\n",
    "                 )->Recipe:\n",
    "    return Recipe(recipe_name=recipe_name, ingredients=ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d04449",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = \"Give me a receipe for chocolate chip cookies\"\n",
    "recipe = c.structured(pr, sp=sysp, tools=[create_recipe])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf791107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Recipe(recipe_name='Chocolate Chip Cookies', ingredients=['flour', 'sugar', 'butter', 'eggs', 'chocolate chips'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5120e8",
   "metadata": {},
   "source": [
    "We see that using tool calling, we can get the model to return the recipe as a recipe object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae3af7",
   "metadata": {},
   "source": [
    "Now let's try a slightly more complicated example with a nested structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turn:\n",
    "    \"\"\"A turn in the conversation.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_a: str, # The first user's message\n",
    "        user_b: str, # The second user's message\n",
    "    ): store_attr()\n",
    "    \n",
    "    __repr__ = basic_repr(['user_a', 'user_b'])\n",
    "    def __str__(self): return \"Turn created.\"\n",
    "\n",
    "class Conversation:\n",
    "    \"\"\"A conversation between two users.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        turns: List[Turn], # The turns in the conversation\n",
    "    ): store_attr()\n",
    "    \n",
    "    __repr__ = basic_repr('turns')\n",
    "    def __str__(self): return \"Conversation created.\"\n",
    "\n",
    "\n",
    "def create_conversation(\n",
    "    user_a_turns: List[str], # List of turns for the first person in the conversation\n",
    "    user_b_turns: List[str] # List of turns for the second person in the conversation\n",
    ")->Conversation:\n",
    "    \"\"\"\n",
    "    This is used to create a conversation between two users.\n",
    "    \"\"\"\n",
    "    return Conversation([Turn(a,b) for a,b in zip(user_a_turns, user_b_turns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6dbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = \"Generate a conversation between a python programmer and a rust programmer.\"\n",
    "conv = c.structured(pr, sp=sysp, tools=[create_conversation])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d09119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.Turn(user_a='Hello, I am a Python programmer. What about you?', user_b='Hi there! I am a Rust programmer.'),\n",
       " __main__.Turn(user_a='Interesting. I have heard Rust is quite fast.', user_b='Yes, Rust is known for its performance and memory safety.'),\n",
       " __main__.Turn(user_a='I see, thanks for the info!', user_b='You are welcome!')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.turns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3eba5",
   "metadata": {},
   "source": [
    "As we can see, the model is able to return the necessary information to create the conversation object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b08bc5",
   "metadata": {},
   "source": [
    "We can also force a particular set of tools to be used using, `tool_choice`. Here's an example of how to do that for genai api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_tool_choice(choose: list)->dict:\n",
    "    return {\"function_calling_config\": {\"mode\": \"ANY\", \"allowed_function_names\": [x.__name__ for x in choose]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5fef41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_calling_config': {'mode': 'ANY',\n",
       "  'allowed_function_names': ['sums']}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_choice = mk_tool_choice([sums])\n",
    "tool_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de626735",
   "metadata": {},
   "source": [
    "We'll use this with the Chat class that we'll create next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eaed74",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8b25c",
   "metadata": {},
   "source": [
    "We'll create a Chat class that will handle formatting of messages and passing along system prompts and tools, so we don't have to worry about doing that manually each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Chat:\n",
    "    def __init__(self,\n",
    "                 model:Optional[str]=None, # Model to use (leave empty if passing `cli`)\n",
    "                 cli:Optional[Client]=None, # Client to use (leave empty if passing `model`)\n",
    "                 sp=None, # Optional system prompt\n",
    "                 tools:Optional[list]=None,  # List of tools to make available\n",
    "                 tool_choice:Optional[str]=None): # Forced tool choice\n",
    "        \"Gemini chat client.\"\n",
    "        assert model or cli\n",
    "        self.c = (cli or Client(model, sp=sp))\n",
    "        self.h,self.sp,self.tools,self.tool_choice = [],sp,tools,tool_choice\n",
    "    \n",
    "    @property\n",
    "    def use(self): return self.c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567fcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(In: 0; Out: 0; Total: 0, [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"Never mention what tools you use.\"\n",
    "chat = Chat(model, sp=sp)\n",
    "chat.c.use, chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _stream(self:Chat, res):\n",
    "    yield from res\n",
    "    self.h += mk_toolres(self.c.result, ns=self.tools, obj=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(genai.GenerativeModel.generate_content)\n",
    "def __call__(self:Chat,\n",
    "             pr=None,  # Prompt / message\n",
    "             temp=0, # Temperature\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             stream=False, # Stream response?\n",
    "             **kwargs):\n",
    "    if isinstance(pr,str): pr = pr.strip()\n",
    "    if pr: self.h.append(mk_msg(pr))\n",
    "    if self.tools: kwargs['tools'] = self.tools\n",
    "    # NOTE: Gemini specifies tool_choice via tool_config\n",
    "    if self.tool_choice: kwargs['tool_config'] = mk_tool_choice(self.tool_choice)\n",
    "    res = self.c(self.h, stream=stream, sp=self.sp, temp=temp, maxtok=maxtok, **kwargs)\n",
    "    if stream: return self._stream(res)\n",
    "    self.h += mk_toolres(self.c.result, ns=self.tools, obj=self)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778295e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Faisal! What can I do for you today? ðŸ˜Š \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'Nice to meet you, Faisal! What can I do for you today? ðŸ˜Š \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 12\n",
       "- candidates_token_count: 16\n",
       "- total_token_count: 28\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Nice to meet you, Faisal! What can I do for you today? \\ud83d\\ude0a \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 12,\n",
       "        \"candidates_token_count\": 16,\n",
       "        \"total_token_count\": 28\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"I'm Faisal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8006a",
   "metadata": {},
   "source": [
    "Now let's make sure that context is passed properly to subsequent calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5374fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your name is Faisal. ðŸ˜Š  Is there anything else I can help you with? \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'Your name is Faisal. ðŸ˜Š  Is there anything else I can help you with? \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 38\n",
       "- candidates_token_count: 17\n",
       "- total_token_count: 55\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Your name is Faisal. \\ud83d\\ude0a  Is there anything else I can help you with? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 38,\n",
       "        \"candidates_token_count\": 17,\n",
       "        \"total_token_count\": 55\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37f240",
   "metadata": {},
   "source": [
    "Let's also make sure that streaming works correctly with the Chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Faisal! ðŸ‘‹ What can I do for you today? ðŸ˜Š \n"
     ]
    }
   ],
   "source": [
    "chat = Chat(model, sp=sp)\n",
    "for o in chat(\"I'm Faisal\", stream=True):\n",
    "    o = contents(o)\n",
    "    if o and isinstance(o, str): print(o, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35d8ea",
   "metadata": {},
   "source": [
    "Let's also make sure that tool use works with the Chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a192f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is 604542+6458932?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = f\"What is {a}+{b}?\"\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3b278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Faisal! How can I help you today? \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'Nice to meet you, Faisal! How can I help you today? \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 72\n",
       "- candidates_token_count: 14\n",
       "- total_token_count: 86\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Nice to meet you, Faisal! How can I help you today? \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 72,\n",
       "        \"candidates_token_count\": 14,\n",
       "        \"total_token_count\": 86\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"You are a helpful assistant. When using tools, be sure to pass all required parameters, at minimum.\"\n",
    "chat = Chat(model, sp=sp, tools=[sums])\n",
    "r = chat(\"I'm Faisal\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18228faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542.0 and 6458932.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- content: {'parts': [{'function_call': {'name': 'sums', 'args': {'a': 604542.0, 'b': 6458932.0}}}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 8, 'probability': 1, 'blocked': False}, {'category': 9, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 108\n",
       "- candidates_token_count: 29\n",
       "- total_token_count: 137\n",
       "- cached_content_token_count: 0"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"sums\",\n",
       "                  \"args\": {\n",
       "                    \"a\": 604542.0,\n",
       "                    \"b\": 6458932.0\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 108,\n",
       "        \"candidates_token_count\": 29,\n",
       "        \"total_token_count\": 137\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a408b9bd",
   "metadata": {},
   "source": [
    "The model correctly calls the right function in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf082b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'function',\n",
       " 'parts': [name: \"sums\"\n",
       "  response {\n",
       "    fields {\n",
       "      key: \"result\"\n",
       "      value {\n",
       "        string_value: \"7063474.0\"\n",
       "      }\n",
       "    }\n",
       "  }]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.h[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbbf11",
   "metadata": {},
   "source": [
    "If we inspect the history, we can see that the result of the function call has already been added. We can simply call `chat()` to pass this to the model and get a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f61a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "604542 + 6458932 = 7063474. \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': '604542 + 6458932 = 7063474. \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 160\n",
       "- candidates_token_count: 25\n",
       "- total_token_count: 185\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"604542 + 6458932 = 7063474. \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 160,\n",
       "        \"candidates_token_count\": 25,\n",
       "        \"total_token_count\": 185\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d1b5a",
   "metadata": {},
   "source": [
    "Now let's make sure that `tool_choice` works correctly by forcing the model to pick a particular function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fe00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(\n",
    "    a:int, # The number to subtract from\n",
    "    b:int # The amount to subtract\n",
    ") -> int: # Result of subtracting b from a\n",
    "    \"Returns a - b.\"\n",
    "    print(f\"Finding the diff of {a} and {b}\")\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ef89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the diff of 604542.0 and 6458932.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- content: {'parts': [{'function_call': {'name': 'diff', 'args': {'a': 604542.0, 'b': 6458932.0}}}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}, {'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 132\n",
       "- candidates_token_count: 29\n",
       "- total_token_count: 161\n",
       "- cached_content_token_count: 0"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"diff\",\n",
       "                  \"args\": {\n",
       "                    \"a\": 604542.0,\n",
       "                    \"b\": 6458932.0\n",
       "                  }\n",
       "                }\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 132,\n",
       "        \"candidates_token_count\": 29,\n",
       "        \"total_token_count\": 161\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = \"You are a helpful assistant. When using tools, be sure to pass all required parameters, at minimum.\"\n",
    "chat = Chat(model, sp=sp, tools=[sums, diff], tool_choice=[diff])\n",
    "r = chat(f\"What is {a}+{b}?\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f1673",
   "metadata": {},
   "source": [
    "We can see that the model calls the function specified by `tool_choice` even though the prompt asks for a summation, which is the expected behvior in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58508b0e",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": null,
     "metadata": {
      "image/jpeg": {
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = Path('./samples/puppy.jpg')\n",
    "display.Image(filename=fn, width=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc3a59",
   "metadata": {},
   "source": [
    "Now that we are passing more than just text, will need a helper function to upload media using Gemini's File API, which is the recomended way of passing media to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def media_msg(fn: Path)->dict:\n",
    "    f = genai.upload_file(fn)\n",
    "    return {'file_data': {'mime_type': f.mime_type, 'file_uri': f.uri}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1316e",
   "metadata": {},
   "source": [
    "Let's also update how we pass in text type messages, to be consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def text_msg(s:str)->dict:\n",
    "    return {'text': s}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105009c",
   "metadata": {},
   "source": [
    "And finally lets had a helper funciton for make content correctly handles text and other media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed657bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _mk_content(src):\n",
    "    \"Create appropriate content data structure based on type of content\"\n",
    "    if isinstance(src,str): return text_msg(src)\n",
    "    else: return media_msg(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a5f034",
   "metadata": {},
   "source": [
    "Now let's make sure it properly handles text vs. Path objects for media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3befbdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Hi'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mk_content(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ad3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_data': {'mime_type': 'image/jpeg',\n",
       "  'file_uri': 'https://generativelanguage.googleapis.com/v1beta/files/6ds7015edz5e'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mk_content(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8705f",
   "metadata": {},
   "source": [
    "And now we need to update mk_msg to be able to handle multimedia messages correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35703ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_msg(content, role='user', **kw):\n",
    "    \"Create a message\"\n",
    "    if isinstance(content, FunctionResponse): return content\n",
    "    if isinstance(content, GenerateContentResponse): return find_block(content)\n",
    "    if content is not None and not isinstance(content, list): content=[content]\n",
    "    if role == 'user': content = [_mk_content(o) for o in content] if content else ''\n",
    "    return dict(role=role, parts=content, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65879c1d",
   "metadata": {},
   "source": [
    "Now, we should just be able to pass a list of multimedia content to our Chat client and it should be able to handle it all under the hood. Let's test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79448474",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061388df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The flowers in the image are purple. \n",
       "\n",
       "\n",
       "<details>\n",
       "\n",
       "- content: {'parts': [{'text': 'The flowers in the image are purple. \\n'}], 'role': 'model'}\n",
       "- finish_reason: 1\n",
       "- index: 0\n",
       "- safety_ratings: [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]\n",
       "- token_count: 0\n",
       "- grounding_attributions: []\n",
       "- prompt_token_count: 270\n",
       "- candidates_token_count: 8\n",
       "- total_token_count: 278\n",
       "- cached_content_token_count: 0\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The flowers in the image are purple. \\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 270,\n",
       "        \"candidates_token_count\": 8,\n",
       "        \"total_token_count\": 278\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"In brief, what color flowers are in this image?\"\n",
    "chat([fn, q])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1710a811",
   "metadata": {},
   "source": [
    "Hooray! That works, let's double check the history to make sure that everything is properly formatted and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee65a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'parts': [{'file_data': {'mime_type': 'image/jpeg',\n",
       "     'file_uri': 'https://generativelanguage.googleapis.com/v1beta/files/op2zztctwxye'}},\n",
       "   {'text': 'In brief, what color flowers are in this image?'}]},\n",
       " parts {\n",
       "   text: \"The flowers in the image are purple. \\n\"\n",
       " }\n",
       " role: \"model\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133fca0",
   "metadata": {},
   "source": [
    "## Other Media (audio, video, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40acd644",
   "metadata": {},
   "source": [
    "Unlike ChatGPT and Claude, Gemini models can also handle audio and video inputs. Since we're using Gemini's File API for handling multimedia content, what we have should just work, except we'll need to make one small modification to the `media_msg` function ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def media_msg(fn: Path)->dict:\n",
    "    print(f\"Uploading media...\", end='')\n",
    "    f = genai.upload_file(fn)\n",
    "    while f.state.name == \"PROCESSING\":\n",
    "        print('.', end='')\n",
    "        time.sleep(2)\n",
    "        f = genai.get_file(f.name)\n",
    "    return {'file_data': {'mime_type': f.mime_type, 'file_uri': f.uri}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94f0f8",
   "metadata": {},
   "source": [
    "Since we're uploading potentially larger files, we need to wait for the upload and process to complete so that the media is ready to be consumed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4\n",
    "# We'll test this with the example from Gemini's docs\n",
    "# video_fn = Path('./GreatRedSpot.mp4')\n",
    "# prompt = \"Summarize this video.\"\n",
    "# chat = Chat(model)\n",
    "# chat([video_fn, prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e841b2",
   "metadata": {},
   "source": [
    "Takes a little while, but works like a charm! Now, let's try an audio file to make sure it also works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03856f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_fn = Path('./samples/attention_is_all_you_need.mp3')\n",
    "# prompt = \"Is the content of this audio file of a related subject matter to the video?\"\n",
    "# chat([audio_fn, prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d9a18",
   "metadata": {},
   "source": [
    "Finally, let's check to make sure pdfs work as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_fn = Path('./samples/attention_is_all_you_need.pdf')\n",
    "# prompt = \"What's mentioned in this pdf that's not mentioned in the previous podcast?\"\n",
    "# chat([pdf_fn, prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1314b9b7",
   "metadata": {},
   "source": [
    "Gemini does a pretty good job here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ad692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Can you generate an exact transcript of the speech in the podcast?\"\n",
    "# chat([prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd1cd6",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f850535a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
