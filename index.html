<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Gaspard is a helper for Google’s Gemini Models">

<title>Gaspard – gaspard</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-92ed5e3cbc5d145d6df6ed0eb00c1a90.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Gaspard – gaspard">
<meta property="og:description" content="Gaspard is a helper for Google’s Gemini Models">
<meta property="og:image" content="https://AnswerDotAI.github.io/gaspard/index_files/figure-html/cell-30-output-1.jpeg">
<meta property="og:site_name" content="gaspard">
<meta name="twitter:title" content="Gaspard – gaspard">
<meta name="twitter:description" content="Gaspard is a helper for Google’s Gemini Models">
<meta name="twitter:image" content="https://AnswerDotAI.github.io/gaspard/index_files/figure-html/cell-30-output-1.jpeg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">gaspard</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./index.html">Gaspard</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Gaspard</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./core.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gaspard’s source</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_toolloop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tool loop</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#install" id="toc-install" class="nav-link active" data-scroll-target="#install">Install</a></li>
  <li><a href="#getting-started" id="toc-getting-started" class="nav-link" data-scroll-target="#getting-started">Getting started</a></li>
  <li><a href="#chat" id="toc-chat" class="nav-link" data-scroll-target="#chat">Chat</a></li>
  <li><a href="#tool-use" id="toc-tool-use" class="nav-link" data-scroll-target="#tool-use">Tool use</a></li>
  <li><a href="#tool-loop" id="toc-tool-loop" class="nav-link" data-scroll-target="#tool-loop">Tool loop</a></li>
  <li><a href="#structured-outputs" id="toc-structured-outputs" class="nav-link" data-scroll-target="#structured-outputs">Structured Outputs</a></li>
  <li><a href="#images" id="toc-images" class="nav-link" data-scroll-target="#images">Images</a></li>
  <li><a href="#other-media" id="toc-other-media" class="nav-link" data-scroll-target="#other-media">Other Media</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/AnswerDotAI/gaspard/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="index.html.md"><i class="bi bi-file-code"></i>CommonMark</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Gaspard</h1>
</div>

<div>
  <div class="description">
    Gaspard is a helper for Google’s Gemini Models
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="install" class="level2">
<h2 class="anchored" data-anchor-id="install">Install</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install gaspard</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="getting-started" class="level2">
<h2 class="anchored" data-anchor-id="getting-started">Getting started</h2>
<p>Follow the <a href="https://aistudio.google.com/app/apikey">instructions</a> to generate an API key, and set it as an evironment variable as shown below:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">GEMINI_API_KEY</span><span class="op">=</span>YOUR_API_KEY</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Gemini’s Python SDK will automatically be installed with Gaspard, if you don’t already have it.</p>
<div id="cell-8" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gaspard <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Gaspard provides models, which lists the models available in the SDK</p>
<div id="cell-10" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>models</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>('gemini-2.0-flash-exp',
 'gemini-exp-1206',
 'learnlm-1.5-pro-experimental',
 'gemini-exp-1121',
 'gemini-1.5-pro',
 'gemini-1.5-flash',
 'gemini-1.5-flash-8b')</code></pre>
</div>
</div>
<p>For our examples we’ll use <code>gemini-2.0-flash-exp</code> since it’s awesome, has a 1M context window and is currently free while in the experimental stage.</p>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> models[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="chat" class="level2">
<h2 class="anchored" data-anchor-id="chat">Chat</h2>
<p>The main interface to Gaspard is the <a href="https://AnswerDotAI.github.io/gaspard/core.html#chat"><code>Chat</code></a> class which provides a stateful interface to the models</p>
<div id="cell-15" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model, sp<span class="op">=</span><span class="st">"""You are a helpful and concise assistant."""</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>chat(<span class="st">"I'm Faisal"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Hi Faisal, it’s nice to meet you!</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: “Hi Faisal, it’s nice to meet you!”}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.04827792942523956</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 14</li>
<li>candidates_token_count: 12</li>
<li>total_token_count: 26</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<div id="cell-16" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> chat(<span class="st">"What's my name?"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Your name is Faisal.</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ‘Your name is Faisal.’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -1.644962443000016e-05</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 35</li>
<li>candidates_token_count: 6</li>
<li>total_token_count: 41</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<p>As you see above, displaying the results of a call in a notebook shows just the message contents, with the other details hidden behind a collapsible section. Alternatively you can print the details:</p>
<div id="cell-18" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>response:
GenerateContentResponse(
    done=True,
    iterator=None,
    result=protos.GenerateContentResponse({
      "candidates": [
        {
          "content": {
            "parts": [
              {
                "text": "Your name is Faisal.\n"
              }
            ],
            "role": "model"
          },
          "finish_reason": "STOP",
          "safety_ratings": [
            {
              "category": "HARM_CATEGORY_HATE_SPEECH",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_HARASSMENT",
              "probability": "NEGLIGIBLE"
            },
            {
              "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
              "probability": "NEGLIGIBLE"
            }
          ],
          "avg_logprobs": -1.644962443000016e-05
        }
      ],
      "usage_metadata": {
        "prompt_token_count": 35,
        "candidates_token_count": 6,
        "total_token_count": 41
      }
    }),
)</code></pre>
</div>
</div>
<p>You can use stream=True to stream the results as soon as they arrive (although you will only see the gradual generation if you execute the notebook yourself, of course!)</p>
<div id="cell-20" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>chat.h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[{'role': 'user', 'parts': [{'text': "I'm Faisal"}, ' ']},
 {'role': 'model', 'parts': ["Hi Faisal, it's nice to meet you!\n"]},
 {'role': 'user', 'parts': [{'text': "What's my name?"}, ' ']},
 {'role': 'model', 'parts': ['Your name is Faisal.\n']}]</code></pre>
</div>
</div>
<div id="cell-21" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> chat(<span class="st">"What's your name? Tell me your story"</span>, stream<span class="op">=</span><span class="va">True</span>): <span class="bu">print</span>(o, end<span class="op">=</span><span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>I don't have a name or a personal story in the way a human does. I am a large language model, created by Google AI. I was trained on a massive amount of text data to be able to communicate and generate human-like text. I don't have a body, feelings, or memories, but I'm here to help you with information and tasks.</code></pre>
</div>
</div>
<p>Woah, welcome back to the land of the living Bard!</p>
</section>
<section id="tool-use" class="level2">
<h2 class="anchored" data-anchor-id="tool-use">Tool use</h2>
<p>Tool use lets the model use external tools.</p>
<p>We use docments to make defining Python functions as ergonomic as possible. Each parameter (and the return value) should have a type, and a docments comment with the description of what it is. As an example we’ll write a simple function that adds numbers together, and will tell us when it’s being called:</p>
<div id="cell-25" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sums(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    a:<span class="bu">int</span>,  <span class="co"># First thing to sum</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    b:<span class="bu">int</span><span class="op">=</span><span class="dv">1</span> <span class="co"># Second thing to sum</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">int</span>: <span class="co"># The sum of the inputs</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Adds a + b."</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Finding the sum of </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">+</span> b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sometimes the model will say something like “according to the sums tool the answer is” – generally we’d rather it just tells the user the answer, so we can use a system prompt to help with this:</p>
<div id="cell-27" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>sp <span class="op">=</span> <span class="st">"Never mention what tools you use."</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll get the model to add up some long numbers:</p>
<div id="cell-29" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>a,b <span class="op">=</span> <span class="dv">604542</span>,<span class="dv">6458932</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> <span class="ss">f"What is </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">+</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">?"</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>pr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'What is 604542+6458932?'</code></pre>
</div>
</div>
<p>To use tools, pass a list of them to Chat:</p>
<div id="cell-31" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model, sp<span class="op">=</span>sp, tools<span class="op">=</span>[sums])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now when we call that with our prompt, the model doesn’t return the answer, but instead returns a <code>function_call</code> message, which means we have to call the named function (tool) with the provided parameters:</p>
<div id="cell-33" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(pr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>str</code></pre>
</div>
</div>
<div id="cell-34" class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> chat(pr)<span class="op">;</span> r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Finding the sum of 604542.0 and 6458932.0</code></pre>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>function_call { name: “sums” args { fields { key: “b” value { number_value: 6458932 } } fields { key: “a” value { number_value: 604542 } } } }</p>
<details>
<ul>
<li>content: {‘parts’: [{‘function_call’: {‘name’: ‘sums’, ‘args’: {‘a’: 604542.0, ‘b’: 6458932.0}}}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -9.219200364896096e-06</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 77</li>
<li>candidates_token_count: 3</li>
<li>total_token_count: 80</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<p>Gaspard handles all that for us – we just have to pass along the message, and it all happens automatically:</p>
<div id="cell-36" class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>chat.h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[{'role': 'user', 'parts': [{'text': 'What is 604542+6458932?'}, ' ']},
 {'role': 'model',
  'parts': [function_call {
     name: "sums"
     args {
       fields {
         key: "b"
         value {
           number_value: 6458932
         }
       }
       fields {
         key: "a"
         value {
           number_value: 604542
         }
       }
     }
   }]},
 {'role': 'user',
  'parts': [name: "sums"
   response {
     fields {
       key: "result"
       value {
         number_value: 7063474
       }
     }
   },
   {'text': ' '}]}]</code></pre>
</div>
</div>
<div id="cell-37" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>chat()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>7063474</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ‘7063474’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.005276891868561506</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 128</li>
<li>candidates_token_count: 8</li>
<li>total_token_count: 136</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<p>We can inspect the history to see what happens under the hood. Gaspard calls the tool with the appropriate variables returned by the <code>function_call</code> message from the model. The result of calling the function is then sent back to the model, which uses that to respond to the user.</p>
<div id="cell-39" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>chat.h[<span class="op">-</span><span class="dv">3</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[{'role': 'model',
  'parts': [function_call {
     name: "sums"
     args {
       fields {
         key: "b"
         value {
           number_value: 6458932
         }
       }
       fields {
         key: "a"
         value {
           number_value: 604542
         }
       }
     }
   }]},
 {'role': 'user',
  'parts': [name: "sums"
   response {
     fields {
       key: "result"
       value {
         number_value: 7063474
       }
     }
   },
   {'text': ' '}]},
 {'role': 'model', 'parts': ['7063474\n']}]</code></pre>
</div>
</div>
<p>You can see how many tokens have been used at any time by checking the <code>use</code> property.</p>
<div id="cell-41" class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>chat.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 205; Out: 11; Total: 216</code></pre>
</div>
</div>
</section>
<section id="tool-loop" class="level2">
<h2 class="anchored" data-anchor-id="tool-loop">Tool loop</h2>
<p>We can do everything needed to use tools in a single step, by using Chat.toolloop. This can even call multiple tools as needed solve a problem. For example, let’s define a tool to handle multiplication:</p>
<div id="cell-44" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mults(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    a:<span class="bu">int</span>,  <span class="co"># First thing to multiply</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    b:<span class="bu">int</span><span class="op">=</span><span class="dv">1</span> <span class="co"># Second thing to multiply</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">int</span>: <span class="co"># The product of the inputs</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Multiplies a * b."</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Finding the product of </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">*</span> b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now with a single call we can calculate <code>(a+b)*2</code> – by passing <code>show_trace</code> we can see each response from the model in the process:</p>
<div id="cell-46" class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model, sp<span class="op">=</span>sp, tools<span class="op">=</span>[sums,mults])</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> <span class="ss">f'Calculate (</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">+</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">)*2'</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>pr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'Calculate (604542+6458932)*2'</code></pre>
</div>
</div>
<div id="cell-47" class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pchoice(r): <span class="bu">print</span>(r.parts[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-48" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> chat.toolloop(pr, trace_func<span class="op">=</span>pchoice)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Finding the sum of 604542.0 and 6458932.0
function_call {
  name: "sums"
  args {
    fields {
      key: "b"
      value {
        number_value: 6458932
      }
    }
    fields {
      key: "a"
      value {
        number_value: 604542
      }
    }
  }
}

Finding the product of 7063474.0 and 2.0
function_call {
  name: "mults"
  args {
    fields {
      key: "b"
      value {
        number_value: 2
      }
    }
    fields {
      key: "a"
      value {
        number_value: 7063474
      }
    }
  }
}

text: "(604542+6458932)*2 = 14126948\n"
</code></pre>
</div>
</div>
<p>We can see from the trace above that the model correctly calls the sums function first to add the numbers inside the parenthesis and then calls the mults function to multiply the result of the summation by <code>2</code>. The response sent back to the user is the actual result after performing the chained tool calls, shown below:</p>
<div id="cell-50" class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>(604542+6458932)*2 = 14126948</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ’(604542+6458932)*2 = 14126948’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.00017791306267359426</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 229</li>
<li>candidates_token_count: 28</li>
<li>total_token_count: 257</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
</section>
<section id="structured-outputs" class="level2">
<h2 class="anchored" data-anchor-id="structured-outputs">Structured Outputs</h2>
<p>If you just want the immediate result from a single tool, use <a href="https://AnswerDotAI.github.io/gaspard/core.html#client.structured"><code>Client.structured</code></a>.</p>
<div id="cell-53" class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>cli <span class="op">=</span> Client(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-54" class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sums(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    a:<span class="bu">int</span>,  <span class="co"># First thing to sum</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    b:<span class="bu">int</span><span class="op">=</span><span class="dv">1</span> <span class="co"># Second thing to sum</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">int</span>: <span class="co"># The sum of the inputs</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Adds a + b."</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Finding the sum of </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">+</span> b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-55" class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>cli.structured(<span class="st">"What is 604542+6458932"</span>, sums)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Finding the sum of 604542.0 and 6458932.0</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>[7063474.0]</code></pre>
</div>
</div>
<p>This is particularly useful for getting back structured information, e.g:</p>
<div id="cell-57" class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> President(BasicRepr):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Information about a president of the United States"</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, </span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>                first:<span class="bu">str</span>, <span class="co"># first name</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>                last:<span class="bu">str</span>, <span class="co"># last name</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>                spouse:<span class="bu">str</span>, <span class="co"># name of spouse</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>                years_in_office:<span class="bu">str</span>, <span class="co"># format: "{start_year}-{end_year}"</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>                birthplace:<span class="bu">str</span>, <span class="co"># name of city</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>                birth_year:<span class="bu">int</span> <span class="co"># year of birth, `0` if unknown</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>        ):</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> re.match(<span class="vs">r'\d</span><span class="sc">{4}</span><span class="vs">-\d</span><span class="sc">{4}</span><span class="vs">'</span>, years_in_office), <span class="st">"Invalid format: `years_in_office`"</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>        store_attr()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-58" class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>cli.structured(<span class="st">"Provide key information about the 3rd President of the United States"</span>, President)[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>President(first='Thomas', last='Jefferson', spouse='Martha Wayles Skelton', years_in_office='1801-1809', birthplace='Shadwell', birth_year=1743.0)</code></pre>
</div>
</div>
</section>
<section id="images" class="level2">
<h2 class="anchored" data-anchor-id="images">Images</h2>
<p>As everyone knows, when testing image APIs you have to use a cute puppy. But, that’s boring, so here’s a baby hippo instead.</p>
<div id="cell-61" class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>img_fn <span class="op">=</span> Path(<span class="st">'samples/baby_hippo.jpg'</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>display.Image(filename<span class="op">=</span>img_fn, width<span class="op">=</span><span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-30-output-1.jpeg" class="img-fluid figure-img" width="200"></p>
</figure>
</div>
</div>
</div>
<p>We create a <a href="https://AnswerDotAI.github.io/gaspard/core.html#chat"><code>Chat</code></a> object as before:</p>
<div id="cell-63" class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For Gaspard, we can simply pass <code>Path</code> objects that repsent the path of the images. To pass multi-part messages, such as an image along with a prompt, we simply pass in a list of items. Note that Gaspard expects each item to be a text or a <code>Path</code> object.</p>
<div id="cell-65" class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>chat([img_fn, <span class="st">"In brief, is happening in the photo?"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Certainly!</p>
In the photo, a person’s hand is gently touching the chin of a baby hippopotamus. The hippo is sitting on the ground and appears to be looking straight at the camera.
<details>
<ul>
<li>content: {‘parts’: [{‘text’: “Certainly!the photo, a person’s hand is gently touching the chin of a baby hippopotamus. The hippo is sitting on the ground and appears to be looking straight at the camera.”}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.3545633316040039</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 268</li>
<li>candidates_token_count: 40</li>
<li>total_token_count: 308</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<p>Under the hood, Gaspard uploads the image using Gemini’s <code>File API</code> and passes a reference to the model. Gemini API will automatically infer the MIME type, and convert it appropriately. NOTE that the image is also included in input tokens.</p>
<div id="cell-67" class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>chat.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 268; Out: 40; Total: 308</code></pre>
</div>
</div>
<p>Alternatively, Gaspard supports creating a multi-stage chat with separate image and text prompts. For instance, you can pass just the image as the initial prompt (in which case the model will make some general comments about what it sees, which can be VERY detailed depending on the model and often begin with “Certainly!” for some reason), and then follow up with questions in additional prompts:</p>
<div id="cell-69" class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>chat(img_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Certainly! Here’s a description of the image you sent:</p>
<p><strong>Overall Scene:</strong></p>
<p>The image is a close-up shot of a baby hippopotamus being gently petted by a human hand. The scene is heartwarming and focuses on the interaction between the adorable hippo calf and the human.</p>
<p><strong>Baby Hippo:</strong></p>
<ul>
<li><strong>Appearance:</strong> The hippo is a very young calf with a plump, rounded body. Its skin is a mottled gray color, with hints of pink especially around its neck and cheeks. Its eyes are dark and soulful, giving it an endearing expression. The calf has a small, broad snout and tiny, rounded ears.</li>
<li><strong>Pose:</strong> The hippo is sitting with its short legs tucked beneath its body. It’s looking directly at the camera with a slightly curious and passive expression.</li>
<li><strong>Texture:</strong> The hippo’s skin appears smooth and moist, suggesting it might be wet or freshly out of the water.</li>
</ul>
<p><strong>Human Hand:</strong></p>
<ul>
<li><strong>Position:</strong> The hand is placed gently under the hippo’s chin and neck, supporting its head. The fingers are slightly curved and not gripping tightly, demonstrating a caring touch.</li>
<li><strong>Texture:</strong> The skin of the hand appears soft and well-maintained.</li>
</ul>
<p><strong>Background:</strong></p>
<ul>
<li><strong>Setting:</strong> The background is out of focus, but it appears to be a rocky, possibly aquatic, environment. The textures in the background are muted and do not detract from the main subjects of the photo.</li>
<li><strong>Date</strong>: There’s a watermark saying “Thailand 9/2024”, indicating the location and date of the image.</li>
</ul>
<p><strong>Mood/Tone:</strong></p>
<ul>
<li>The image evokes a sense of gentleness and tenderness. The close-up perspective and the gentle touch of the hand create a very intimate and sweet scene.</li>
<li>The calf’s innocent expression adds to the overall cuteness and warmth of the image.</li>
</ul>
<p><strong>Overall Impression:</strong></p>
<p>The image captures a beautiful moment of interaction between a human and a very young, vulnerable animal. The photograph emphasizes the gentle nature of the interaction and the sheer adorableness of the baby hippo, making it a very touching and memorable picture.</p>
Let me know if you would like a description from another perspective or have any other questions about the image!
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ’Certainly! Here's a description of the image you sent:*Overall Scene:**image is a close-up shot of a baby hippopotamus being gently petted by a human hand. The scene is heartwarming and focuses on the interaction between the adorable hippo calf and the human. *Baby Hippo:<strong></strong>Appearance:<strong> The hippo is a very young calf with a plump, rounded body. Its skin is a mottled gray color, with hints of pink especially around its neck and cheeks. Its eyes are dark and soulful, giving it an endearing expression. The calf has a small, broad snout and tiny, rounded ears.</strong>Pose:<strong> The hippo is sitting with its short legs tucked beneath its body. It's looking directly at the camera with a slightly curious and passive expression. </strong>Texture:** The hippo's skin appears smooth and moist, suggesting it might be wet or freshly out of the water.*Human Hand:<strong></strong>Position:<strong> The hand is placed gently under the hippo's chin and neck, supporting its head. The fingers are slightly curved and not gripping tightly, demonstrating a caring touch.</strong>Texture:** The skin of the hand appears soft and well-maintained.*Background:<strong></strong>Setting:<strong> The background is out of focus, but it appears to be a rocky, possibly aquatic, environment. The textures in the background are muted and do not detract from the main subjects of the photo.</strong>Date**: There's a watermark saying “Thailand 9/2024”, indicating the location and date of the image.*Mood/Tone:**The image evokes a sense of gentleness and tenderness. The close-up perspective and the gentle touch of the hand create a very intimate and sweet scene.The calf's innocent expression adds to the overall cuteness and warmth of the image.*Overall Impression:**image captures a beautiful moment of interaction between a human and a very young, vulnerable animal. The photograph emphasizes the gentle nature of the interaction and the sheer adorableness of the baby hippo, making it a very touching and memorable picture.me know if you would like a description from another perspective or have any other questions about the image!’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.7025935932741327</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 260</li>
<li>candidates_token_count: 472</li>
<li>total_token_count: 732</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<div id="cell-70" class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>chat(<span class="st">'What direction is the hippo facing?'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>The hippo is facing directly towards the camera.</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ‘The hippo is facing directly towards the camera.’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.06370497941970825</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 742</li>
<li>candidates_token_count: 10</li>
<li>total_token_count: 752</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<div id="cell-71" class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>chat(<span class="st">'What color is it?'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>The hippo is a mottled gray color, with hints of pink especially around its neck and cheeks.</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ‘The hippo is a mottled gray color, with hints of pink especially around its neck and cheeks.’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.08235452175140381</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 760</li>
<li>candidates_token_count: 20</li>
<li>total_token_count: 780</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<p>Note that the image is passed in again for every input in the dialog, via the chat history, so the number of input tokens increases quickly with this kind of chat.</p>
<div id="cell-73" class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>chat.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 1762; Out: 502; Total: 2264</code></pre>
</div>
</div>
</section>
<section id="other-media" class="level2">
<h2 class="anchored" data-anchor-id="other-media">Other Media</h2>
<p>Beyond images, we can also pass in other kind of media to Gaspard, such as audio file, video files, documents, etc.</p>
<p>For example, let’s try to send a pdf file to the model.</p>
<div id="cell-76" class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>pdf_fn <span class="op">=</span> Path(<span class="st">'samples/attention_is_all_you_need.pdf'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-77" class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-78" class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>chat([pdf_fn, <span class="st">"In brief, what are the main ideas of this paper?"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Certainly! Here’s a breakdown of the main ideas presented in the paper “Attention is All You Need”:</p>
<p><strong>Core Contribution: The Transformer Architecture</strong></p>
<ul>
<li><strong>Rejection of Recurrence and Convolution:</strong> The paper proposes a novel neural network architecture called the “Transformer” that moves away from traditional recurrent neural networks (RNNs) and convolutional neural networks (CNNs). These are the common architectures for tasks involving sequence data.</li>
<li><strong>Sole Reliance on Attention:</strong> The Transformer relies solely on the “attention” mechanism to capture relationships within input and output sequences. This is the core novel idea and is in contrast to models using attention <em>in addition to</em> RNNs or CNNs.</li>
<li><strong>Parallelizable:</strong> By removing recurrence, the Transformer is highly parallelizable, which allows for faster training, especially on GPUs.</li>
<li><strong>Attention-Based Encoder-Decoder:</strong> The Transformer uses an encoder-decoder architecture, like other sequence-to-sequence models, but the encoder and decoder are based on self-attention mechanisms rather than RNNs or CNNs.</li>
</ul>
<p><strong>Key Components of the Transformer:</strong></p>
<ul>
<li><strong>Multi-Head Attention:</strong> The Transformer uses multiple “attention heads,” each learning different dependencies. This allows the model to capture information from different representation sub-spaces.
<ul>
<li><strong>Self-Attention:</strong> Attention mechanism is applied on the same sequence (e.g.&nbsp;input to input or output to output), to capture relations within the sequence itself.</li>
<li><strong>Encoder-Decoder Attention:</strong> Attention mechanism is applied on two sequences (encoder and decoder output) to align sequences between the source and target.</li>
</ul></li>
<li><strong>Scaled Dot-Product Attention:</strong> A specific form of attention that uses dot products to calculate the attention weights with a scaling factor to stabilize the training.</li>
<li><strong>Position-wise Feed-Forward Networks:</strong> Fully connected networks are applied to each position separately after attention to add non-linearity.</li>
<li><strong>Positional Encoding:</strong> Since the Transformer doesn’t have inherent recurrence or convolutions, positional encodings are added to the input embeddings to encode the sequence order.</li>
</ul>
<p><strong>Experimental Results and Impact:</strong></p>
<ul>
<li><strong>Superior Translation Quality:</strong> The paper demonstrates the effectiveness of the Transformer on machine translation tasks (English-to-German and English-to-French). The models achieve state-of-the-art results with significant BLEU score improvements over existing models including RNN and CNN based approaches.</li>
<li><strong>Faster Training:</strong> They show that the Transformer achieves those state-of-the-art results with much less training time compared to other architectures, showing the benefit of parallelization.</li>
<li><strong>Generalization to Other Tasks:</strong> The Transformer is also shown to work well on English constituency parsing, highlighting its ability to handle other sequence-based problems.</li>
<li><strong>Interpretability:</strong> Through attention visualizations, the paper also suggests that the model learns to capture structural information in the input, making it more interpretable than recurrent methods.</li>
</ul>
<p><strong>In Essence:</strong></p>
<p>The paper argues for attention as a foundational building block for sequence processing, dispensing with the need for recurrence and convolutions. It introduces the Transformer, a model that leverages attention mechanisms to achieve both better performance and faster training, setting a new state-of-the-art baseline for many tasks such as machine translation.</p>
<p>Let me know if you’d like any specific aspect clarified further!</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ’Certainly! Here's a breakdown of the main ideas presented in the paper “Attention is All You Need”:*Core Contribution: The Transformer Architecture<strong></strong>Rejection of Recurrence and Convolution:<strong> The paper proposes a novel neural network architecture called the “Transformer” that moves away from traditional recurrent neural networks (RNNs) and convolutional neural networks (CNNs). These are the common architectures for tasks involving sequence data.</strong>Sole Reliance on Attention:<strong> The Transformer relies solely on the “attention” mechanism to capture relationships within input and output sequences. This is the core novel idea and is in contrast to models using attention <em>in addition to</em> RNNs or CNNs.</strong>Parallelizable:<strong> By removing recurrence, the Transformer is highly parallelizable, which allows for faster training, especially on GPUs.</strong>Attention-Based Encoder-Decoder:** The Transformer uses an encoder-decoder architecture, like other sequence-to-sequence models, but the encoder and decoder are based on self-attention mechanisms rather than RNNs or CNNs.*Key Components of the Transformer:<strong></strong>Multi-Head Attention:<strong> The Transformer uses multiple “attention heads,” each learning different dependencies. This allows the model to capture information from different representation sub-spaces.</strong>Self-Attention:<strong> Attention mechanism is applied on the same sequence (e.g.&nbsp;input to input or output to output), to capture relations within the sequence itself.</strong>Encoder-Decoder Attention:<strong> Attention mechanism is applied on two sequences (encoder and decoder output) to align sequences between the source and target.</strong>Scaled Dot-Product Attention:<strong> A specific form of attention that uses dot products to calculate the attention weights with a scaling factor to stabilize the training.</strong>Position-wise Feed-Forward Networks:<strong> Fully connected networks are applied to each position separately after attention to add non-linearity.</strong>Positional Encoding:** Since the Transformer doesn't have inherent recurrence or convolutions, positional encodings are added to the input embeddings to encode the sequence order.*Experimental Results and Impact:<strong></strong>Superior Translation Quality:<strong> The paper demonstrates the effectiveness of the Transformer on machine translation tasks (English-to-German and English-to-French). The models achieve state-of-the-art results with significant BLEU score improvements over existing models including RNN and CNN based approaches.</strong>Faster Training:<strong> They show that the Transformer achieves those state-of-the-art results with much less training time compared to other architectures, showing the benefit of parallelization.</strong>Generalization to Other Tasks:<strong> The Transformer is also shown to work well on English constituency parsing, highlighting its ability to handle other sequence-based problems.</strong>Interpretability:** Through attention visualizations, the paper also suggests that the model learns to capture structural information in the input, making it more interpretable than recurrent methods.*In Essence:**paper argues for attention as a foundational building block for sequence processing, dispensing with the need for recurrence and convolutions. It introduces the Transformer, a model that leverages attention mechanisms to achieve both better performance and faster training, setting a new state-of-the-art baseline for many tasks such as machine translation.me know if you'd like any specific aspect clarified further!’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -0.7809832342739763</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 14943</li>
<li>candidates_token_count: 696</li>
<li>total_token_count: 15639</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<p>We can pass in audio files in the same way.</p>
<div id="cell-80" class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>audio_fn <span class="op">=</span> Path(<span class="st">'samples/attention_is_all_you_need.mp3'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-81" class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> <span class="st">"This is a podcast about the same paper. What important details from the paper are not in the podcast?"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-82" class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>chat([audio_fn, pr])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Okay, let’s analyze what details were missing from the podcast discussion of “Attention is All You Need”. Here are some of the key aspects not fully covered:</p>
<p><strong>1. Deeper Dive into the Math and Mechanics:</strong></p>
<ul>
<li><strong>Detailed Attention Formula:</strong> The podcast mentions “scaled dot product attention” but doesn’t delve into the actual mathematical formula used to calculate the attention weights:
<ul>
<li><code>Attention(Q, K, V) = softmax((QK^T) / sqrt(d_k)) * V</code> (where Q=query, K=key, V=value, and d_k is the dimension of the key)</li>
</ul></li>
<li><strong>Query, Key, Value:</strong> While mentioned, the exact nature of how Query, Key and Values are generated from input is never made explicit. How are these generated by linear transformations is an essential aspect.</li>
<li><strong>The role of the Mask:</strong> The mask in decoder’s self-attention is also not covered in depth. Masking is essential for the auto-regressive nature of the output sequence.</li>
<li><strong>Positional Encoding Equations:</strong> The podcast mentioned positional encoding but not the specific sine and cosine formulas and their purpose which are key to how the model retains position information.
<ul>
<li><code>PE(pos, 2i) = sin(pos/10000^(2i/d_model))</code></li>
<li><code>PE(pos, 2i+1) = cos(pos/10000^(2i/d_model))</code></li>
</ul></li>
<li><strong>Detailed explanation of how d_model, d_k, d_v and head dimension relate.</strong> This is essential to understanding the parameter counts in the model.</li>
</ul>
<p><strong>2. Architectural Details and Hyperparameters:</strong></p>
<ul>
<li><strong>Number of Layers and Model Dimensions:</strong> The paper uses 6 layers both on the encoder and decoder side in their basic and large models. The exact dimensionality of the model itself is also crucial to understanding its capacity. The podcast only mentions that they are stacked.</li>
<li><strong>Feed Forward Layer Details:</strong> The point-wise feed-forward network’s dimensionality is essential for model performance. The podcast does not go into depth about it and the dimensionality being used d_ff=2048 is key.</li>
<li><strong>Dropout and Label Smoothing:</strong> They are mentioned as a type of regularization, but the specific rates of 0.1 for the base model are never mentioned nor is the label smoothing rate of 0.1. These details are important for reproducibility and performance.</li>
<li><strong>Optimization Details:</strong> There is also no mention of the Adam Optimizer’s Beta parameters of β₁ = 0.9, β2 = 0.98 and € = 10-9. The paper introduces a specific learning rate decay that is not discussed by name.</li>
</ul>
<p><strong>3. Analysis and Experiments:</strong></p>
<ul>
<li><strong>Comparison to other attention-based models:</strong> The paper explains its motivations in relation to other attention-based models (such as memory networks).</li>
<li><strong>Model variation experiments:</strong> The paper contains detailed experiments varying attention head number and dimensionality, different position encoding options, and impact of dropout and size that are not discussed.</li>
<li><strong>Computational Complexity:</strong> The paper explains detailed complexity analysis for different layer types (Recurrent, Convolutional etc) and their implications for training performance, which is only vaguely discussed in the podcast.</li>
<li><strong>Attention Interpretations:</strong> The paper visually highlights patterns in attention weights which provide intuition on what the model is learning, which is not really discussed by name. This allows insights into how the model handles long-distance dependencies.</li>
</ul>
<p><strong>4. Technical Implementation:</strong></p>
<ul>
<li><strong>Byte-pair encoding:</strong> While mentioned, this subword approach and its impact on vocabulary size and performance is never fully discussed.</li>
<li><strong>Batching:</strong> Batching of training examples using the total sequence length is discussed, but the method of how they are batched in terms of approximately 25000 tokens is not explicit in the podcast.</li>
<li><strong>Ensemble method:</strong> Details about how checkpointing and averaging are used to generate model predictions is missing.</li>
</ul>
<p><strong>5. Broader Context and Future Work</strong></p>
<ul>
<li><strong>Why sinusoidal encodings:</strong> The paper specifically states that they hypothesized that using fixed functions for position encoding should be better than learning them, this explanation is not given in the podcast.</li>
<li><strong>Future Directions:</strong> The paper explicitly lays out plans to extend the transformer to handle larger inputs using locality restrictions and applying them to other modalities, which was alluded to, but not explored with the same depth.</li>
</ul>
<p><strong>In Summary:</strong></p>
<p>The podcast provides a good overview of the high-level ideas of the paper, but it omits several crucial technical details, mathematical equations, model architecture configurations, and experimental analysis. These omissions are quite critical for fully grasping the novelty and impact of the paper’s findings, and for anyone interested in implementing or extending the model. The podcast lacks the quantitative analysis and model variations that the paper presents.</p>
<details>
<ul>
<li>content: {‘parts’: [{‘text’: ’Okay, let's analyze what details were missing from the podcast discussion of “Attention is All You Need”. Here are some of the key aspects not fully covered:*1. Deeper Dive into the Math and Mechanics:<strong></strong>Detailed Attention Formula:<strong> The podcast mentions “scaled dot product attention” but doesn't delve into the actual mathematical formula used to calculate the attention weights:<code>Attention(Q, K, V) = softmax((QK^T) / sqrt(d_k)) * V</code> (where Q=query, K=key, V=value, and d_k is the dimension of the key)</strong>Query, Key, Value:<strong> While mentioned, the exact nature of how Query, Key and Values are generated from input is never made explicit. How are these generated by linear transformations is an essential aspect.</strong>The role of the Mask:<strong> The mask in decoder's self-attention is also not covered in depth. Masking is essential for the auto-regressive nature of the output sequence.</strong>Positional Encoding Equations:<strong> The podcast mentioned positional encoding but not the specific sine and cosine formulas and their purpose which are key to how the model retains position information.<code>PE(pos, 2i) = sin(pos/10000^(2i/d_model))</code><code>PE(pos, 2i+1) = cos(pos/10000^(2i/d_model))</code></strong>Detailed explanation of how d_model, d_k, d_v and head dimension relate.** This is essential to understanding the parameter counts in the model.*2. Architectural Details and Hyperparameters:<strong></strong>Number of Layers and Model Dimensions:<strong> The paper uses 6 layers both on the encoder and decoder side in their basic and large models. The exact dimensionality of the model itself is also crucial to understanding its capacity. The podcast only mentions that they are stacked.</strong>Feed Forward Layer Details:<strong> The point-wise feed-forward network's dimensionality is essential for model performance. The podcast does not go into depth about it and the dimensionality being used d_ff=2048 is key.</strong>Dropout and Label Smoothing:<strong> They are mentioned as a type of regularization, but the specific rates of 0.1 for the base model are never mentioned nor is the label smoothing rate of 0.1. These details are important for reproducibility and performance.</strong>Optimization Details:** There is also no mention of the Adam Optimizer's Beta parameters of β₁ = 0.9, β2 = 0.98 and € = 10-9. The paper introduces a specific learning rate decay that is not discussed by name.*3. Analysis and Experiments:<strong></strong>Comparison to other attention-based models:<strong> The paper explains its motivations in relation to other attention-based models (such as memory networks).</strong>Model variation experiments:<strong> The paper contains detailed experiments varying attention head number and dimensionality, different position encoding options, and impact of dropout and size that are not discussed.</strong>Computational Complexity:<strong> The paper explains detailed complexity analysis for different layer types (Recurrent, Convolutional etc) and their implications for training performance, which is only vaguely discussed in the podcast.</strong>Attention Interpretations:** The paper visually highlights patterns in attention weights which provide intuition on what the model is learning, which is not really discussed by name. This allows insights into how the model handles long-distance dependencies.*4. Technical Implementation:<strong></strong>Byte-pair encoding:<strong> While mentioned, this subword approach and its impact on vocabulary size and performance is never fully discussed.</strong>Batching:<strong> Batching of training examples using the total sequence length is discussed, but the method of how they are batched in terms of approximately 25000 tokens is not explicit in the podcast.</strong>Ensemble method:** Details about how checkpointing and averaging are used to generate model predictions is missing.*5. Broader Context and Future Work<strong></strong>Why sinusoidal encodings:<strong> The paper specifically states that they hypothesized that using fixed functions for position encoding should be better than learning them, this explanation is not given in the podcast.</strong>Future Directions:** The paper explicitly lays out plans to extend the transformer to handle larger inputs using locality restrictions and applying them to other modalities, which was alluded to, but not explored with the same depth.*In Summary:**podcast provides a good overview of the high-level ideas of the paper, but it omits several crucial technical details, mathematical equations, model architecture configurations, and experimental analysis. These omissions are quite critical for fully grasping the novelty and impact of the paper's findings, and for anyone interested in implementing or extending the model. The podcast lacks the quantitative analysis and model variations that the paper presents.’}], ‘role’: ‘model’}</li>
<li>finish_reason: 1</li>
<li>safety_ratings: [{‘category’: 8, ‘probability’: 1, ‘blocked’: False}, {‘category’: 10, ‘probability’: 1, ‘blocked’: False}, {‘category’: 7, ‘probability’: 1, ‘blocked’: False}, {‘category’: 9, ‘probability’: 1, ‘blocked’: False}]</li>
<li>avg_logprobs: -1.2337962527821222</li>
<li>token_count: 0</li>
<li>grounding_attributions: []</li>
<li>prompt_token_count: 23502</li>
<li>candidates_token_count: 1039</li>
<li>total_token_count: 24541</li>
<li>cached_content_token_count: 0</li>
</ul>
</details>
</div>
</div>
<p>You should be careful and monitor usage as the token usage rack up really fast!</p>
<div id="cell-84" class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>chat.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 38445; Out: 1735; Total: 40180</code></pre>
</div>
</div>
<p>We can also use structured outputs with multi-modal data:</p>
<div id="cell-86" class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AudioMetadata(BasicRepr):</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Class to hold metadata for audio files"""</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>        n_speakers:<span class="bu">int</span>, <span class="co"># Number of speakers</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>        topic:<span class="bu">str</span>, <span class="co"># Topic discussed</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>        summary:<span class="bu">str</span>, <span class="co"># 100 word summary</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>        transcript:<span class="bu">list</span>[<span class="bu">str</span>], <span class="co"># Transcript of the audio segmented by speaker</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>    ): store_attr()</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> <span class="st">"Extract the necessary information from the audio."</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-87" class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>audio_md <span class="op">=</span> cli.structured(mk_msgs([[audio_fn, pr]]), tools<span class="op">=</span>[AudioMetadata])[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-88" class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of speakers: </span><span class="sc">{</span>audio_md<span class="sc">.</span>n_speakers<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Topic: </span><span class="sc">{</span>audio_md<span class="sc">.</span>topic<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Summary: </span><span class="sc">{</span>audio_md<span class="sc">.</span>summary<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>transcript <span class="op">=</span> <span class="st">'</span><span class="ch">\n</span><span class="st">-'</span>.join(<span class="bu">list</span>(audio_md.transcript)[:<span class="dv">10</span>])</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Transcript: </span><span class="sc">{</span>transcript<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of speakers: 2.0
Topic: Machine Learning and NLP
Summary: This podcast discusses the 'Attention is All You Need' research paper by Vaswani et al., focusing on the Transformer model's architecture, its use of attention mechanisms, and its performance on translation tasks.
Transcript: Welcome to our podcast, where we dive into groundbreaking research papers. Today, we're discussing 'Attention is all you need' by Vaswani at all. Joining us is an expert in machine learning. Welcome.
-Thanks for having me. I'm excited to discuss this revolutionary paper.
-Let's start with the core idea. What's the main thrust of this research?
-The paper introduces a new model architecture called the Transformer, which is based entirely on attention mechanisms. It completely does away with recurrence and convolutions, which were staples in previous sequence transduction models.
-That sounds like a significant departure from previous approaches. What motivated this radical change?
-The main motivation was to address limitations in previous models, particularly the sequential nature of processing in RNNs. This sequential computation hindered parallelization and made it challenging to learn long-range dependencies in sequences.
-Could you explain what attention mechanisms are, and why they're so crucial in this model?
-Certainly. Attention allows the model to focus on different parts of the input sequence when producing each part of the output. In the Transformer, they use a specific type called scaled dot product attention and extend it to multi-head attention, which lets the model jointly attend to information from different representation subspaces.
-Fascinating. How does the Transformer's architecture differ from previous models?
-The Transformer uses a stack of identical layers for both the encoder and decoder. Each layer has two main components, a multi-head self-attention mechanism, and a position-wise fully connected feed-forward network. This structure allows for more parallelization and efficient computation.</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/AnswerDotAI\.github\.io\/gaspard");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/AnswerDotAI/gaspard/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>